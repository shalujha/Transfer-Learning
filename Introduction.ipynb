{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Of Transfer Learning:\n",
    "-  we will learn from experience, i.e something which we have not done yet, but we will learn from other people's experience through newspaper or insights.\n",
    "- suppose we have a very small dataset, and we feed it to a very complex model, then this mmodel will tend to overfit , coz the dataset is very small, this is where Transfer Learning comes into practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning:\n",
    "-   The idea of transfer learning is to use Pretrained models like:\n",
    "-   Alexnet(we dont use it now a days coz it has sooo many parameters and takes a lot of time in execution or precisely training, it takes a lot of space also).\n",
    "-   VGG: VGG16 or VGG19 (we can use this , but now there are more powerful network than this , which we are using now a days).\n",
    "-   Resnet-50, Resnet-101: we are using this now a days, its a powerful network.\n",
    "-   Inception\n",
    "-   Resnet_Inception- V1,V2,V3,V4\n",
    "-   Mobilenets: lesser no of parameters and thus take less time to compute, so if we want to make a lighter network, we use mobilenet model., it uses Depth_Wise Convolution.\n",
    "- Imagenet challange was held from 2012 to 2018, and every year there was a winner.\n",
    "- we can import it from Keras and Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Architecture Of Pretrained Model\n",
    "-   the general model consists of a convolution base which includes, cnn layers, max pooling, and average pooling and after that there is a classifier, which gives the probability of classes.\n",
    "-   the convolution base is basically a feature extractor , which gives features as output , which becomes input to the MLP, which further tells the probability of class or which tells that these features belongs to which class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are two ways to do a transfer learning -\n",
    "-  Feature Extraction\n",
    "-  Fine Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction:\n",
    "-  lets understand this by an example: suppose we provide imagenet dataset to the convolution base , which is a very large datset, it means the convolution base will extract generic features.\n",
    "- As You go deep into the network,the effective receptive field increases, it means from the deeper layers , we will be able to see large part of image.\n",
    "-  after that we will provide this generic features as an input to the classifier or mlp and mlp will predict the class, whose properties are given as an input.\n",
    "- suppose we have to classify between three classes , then what we will do is , we will use a pretrained model which gives probability from only three classes and not 1000 classes. the mlp will be replaced by a pre trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Applications are deep learning models, that are made available alongside Pretrained Weights, These models are used for predictions, Feature Extraction and fine Tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models For Image Classification with Weights Trained on ImageNet.\n",
    "-  Xception\n",
    "-  VGG16\n",
    "-  VGG19\n",
    "-  ResNet, ResNetV2, ResNeXt\n",
    "-  InceptionV3\n",
    "-  InceptionResNetV2\n",
    "-  MobileNet\n",
    "-  MobileNetV2\n",
    "-  DenseNet\n",
    "-  NASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  MobileNet are mobile friendly. They Save this Pre trained model in Few MBs.\n",
    "-  MobileNet(70%) and VGG(71%) has similar Accuracy.\n",
    "-  Resnets and Inceptions has increased accuracy but they are complex models with more no of parameters, and takes lot of computations and more space in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input,decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1030 19:42:02.720694  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1030 19:42:03.556419  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1030 19:42:03.854013  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1030 19:42:03.987766  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1030 19:42:03.988784  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1030 19:42:05.037709  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1030 19:42:05.199683  5916 deprecation_wrapper.py:119] From c:\\users\\ayush\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model=ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an image\n",
    "def readImage(path):\n",
    "    img_path=path\n",
    "    img=image.load_img(img_path,target_size=(224,224))\n",
    "    X=image.img_to_array(img)\n",
    "    X=np.expand_dims(X,axis=0)\n",
    "    X=preprocess_input(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted : [('n02504458', 'African_elephant', 0.4484266), ('n01871265', 'tusker', 0.38977295), ('n02504013', 'Indian_elephant', 0.16171849)]\n"
     ]
    }
   ],
   "source": [
    "X=readImage('image.jpg')\n",
    "pred=model.predict(X)\n",
    "# decode the results into a list of tuples(class, description, results)\n",
    "#one such list for each samples in the batch.\n",
    "print('predicted :',decode_predictions(pred,top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted : [('n07248320', 'book_jacket', 0.3282751), ('n03045698', 'cloak', 0.21592447), ('n04209133', 'shower_cap', 0.08834293)]\n"
     ]
    }
   ],
   "source": [
    "X=readImage('imag2.jpg')\n",
    "pred=model.predict(X)\n",
    "# decode the results into a list of tuples(class, description, results)\n",
    "#one such list for each samples in the batch.\n",
    "print('predicted :',decode_predictions(pred,top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted : [('n02807133', 'bathing_cap', 0.587708), ('n03787032', 'mortarboard', 0.12531835), ('n02669723', 'academic_gown', 0.081210546)]\n"
     ]
    }
   ],
   "source": [
    "X=readImage('image3.jpg')\n",
    "pred=model.predict(X)\n",
    "# decode the results into a list of tuples(class, description, results)\n",
    "#one such list for each samples in the batch.\n",
    "print('predicted :',decode_predictions(pred,top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not so good prediction for image2 and image3 because maybe this class is not present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All these pretrained model described above are trained on imagenet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when you are using this imagenet dataset, dont vary the no of classes parameter to any other value. it should be 1000 only.\n",
    "-  there is a parameter called include_top=true, which means if u just have to extract features , we dont need to use classifier, so next time we will make our own classifier, based on our requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Models:\n",
    "-  Since modern covnets take 2-3 weeks to train on a dataset like imagenet, it is common to see people release their final covnets checkpoints(weights) for the benifit of others who can use the network directly without implementing it from scratch.\n",
    "- This type of network is advantageous when we have to classify from 1000 classes or we have to predict generic class.\n",
    "- when there is a need of a particular class or lets say we have to predict whether its a cat, dog, or chimpanzee then fine tuning comes into picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In many scenarios you will need some custom classes which is not in imagenet. you just want to do classiication within 4 classes lets say.\n",
    "- The first thing you can do is covnet as a feature extractor,you have the classifier part that accept the vector or features, and that goes to mlp and to further classification.\n",
    "- what we can do in covnet as a feature extractor is Take a Covnet Pretrained on ImageNet, remove the last fully connected layers(the layer's outputs are the 1000 classes scores for a different task like imagenet) then treat rest of the covnet as a fixed feature extractor for the new dataset.\n",
    "- Now for any input image, covnet will act as a feature extractor and then we will implement our own linear classifier / svm for the new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning the ConvNet:\n",
    "-  the idea is to not only replace and retrain the classifieron the top of convnet on the new Dataset, but also fine tune weights of pretrained model, here fine tuning means minor updation of weights, suppose the weight is 1.45 and if we vary it to 1.47 then validation accuracy increases , so we will do this.\n",
    "-  it is possible to fine - tune all the layers of convnet or its possible to keep some of the earlier layers fixed,(due to overfitting concerns) and only fine tube higher levels of network.\n",
    "- In fine tuning, learning_rate should be very small, because when you are going to apply weight update rule,because if the learning rate is large, we will effectively destroy weight learnt in  layers.\n",
    "-  we will just freeze the low level layers and fine tune the high level layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When and How to Fine Tune:\n",
    "-  if the new dataset is small and similar to orignal dataset(Imagenet), then its not a good idea to fine tune the convnet due to overfitting concerns.\n",
    "-  if the new dataset is large and similar to orignal dataset, since we have more data, we are more confident that we wont overfit, if we will try to fine tune through the full network.\n",
    "-  if the new dataset is very small and ver different from the orignal dataset, since the data is very small,it is likely best to only train a linear classifier, since the dataset is very different, it might not be best to train a classifier from the top of network,which contains more dataset specific features, . Instead it might work better to train svm classifier from activations somewhere earlier in the network.\n",
    "- if the new dataset is large and different from orignal dataset, since the dataset is very large, we may expect that we can afford to train a covnet from scratch . However, In practice, it is very often  still beneficial, to initialise with weights,  from a pretrained model. In this case, we would have enough data and confidence to fine tune  through entire network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate:\n",
    "- It is common to use  smaller learning rate for convnet weights, that are being fine tuned,in comparison to the weights of new linear classifier that computes the class scores. This is because we expect that the convnets weights are relatively good so we dont wish to destroy them too quickly and too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
